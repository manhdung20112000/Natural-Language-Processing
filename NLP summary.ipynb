{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before extract data into vector using `Bag of Words`, `TF`, ... We need to clean the text data and this process to prepare (or clean) text data before encoding is called **text preprocessing**.\n",
    "\n",
    "***There are 3 main components:***\n",
    "- Tokenization\n",
    "- Normalization\n",
    "- Noise removal\n",
    "\n",
    "Paragraphs can be tokenized into sentences and sentences can be tokenized into words, it's **Tokenization**. **Normalization** aims to put all text on a level playing field, e.g., converting all characters to lowercase. **Noise removal** cleans up the text, e.g., remove extra whitespaces.\n",
    "\n",
    "***Text Preprocessing steps:*** \n",
    "- Remove HTML tags\n",
    "- Remove extra whitespaces\n",
    "- Convert accented characters to ASCII characters\n",
    "- Expand contractions\n",
    "- Remove special characters\n",
    "- Lowercase all texts\n",
    "- Convert number words to numeric form\n",
    "- Remove numbers\n",
    "- Remove stopwords\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manhd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manhd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manhd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing URL\n",
    "def clean_url (text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "#removing special characters\n",
    "def clean_special_character (text):\n",
    "    return re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "#removing upper case characters\n",
    "def clean_uppercase (text):\n",
    "    return str(text).lower()\n",
    "\n",
    "#sentence seqmentation\n",
    "def sent_tokenization (text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "#tokenization\n",
    "def tokenization (text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "#removing stop words\n",
    "def clean_stop_word (tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "#steamming\n",
    "def steam (tokens):\n",
    "    return [PorterStemmer().stem(token) for token in tokens]\n",
    "\n",
    "#lenmatization\n",
    "def lenmatization (tokens):\n",
    "    return [WordNetLemmatizer().lemmatize(word=token, pos='v') for token in tokens]\n",
    "\n",
    "#remove the words having length <= 2\n",
    "def clean_length (tokens):\n",
    "    return [token for token in tokens if len(token) > 2]\n",
    "\n",
    "#convert back to string\n",
    "def convert_2_string (text):\n",
    "    return ' '.join(text)\n",
    "\n",
    "#apply all cleaner\n",
    "def clean (text):\n",
    "    res = clean_url(text)\n",
    "    res = clean_special_character(res)\n",
    "    res = clean_uppercase(res)\n",
    "    res = tokenization(res)\n",
    "    res = clean_stop_word(res)\n",
    "    res = lenmatization(res)\n",
    "    res = clean_length(res)\n",
    "    return convert_2_string(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " lerxst wam umd edu thing subject car nntp post host rac wam umd edu organization university maryland college park line wonder anyone could enlighten car saw day door sport car look late early call bricklin doors really small addition front bumper separate rest body know anyone tellme model name engine specs years production car make history whatever info funky look car please mail thank bring neighborhood lerxst\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "example = twenty_train.data[0]\n",
    "after_clean = clean(example)\n",
    "print(example, after_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction** is used to transform each text into a numerical representation in the form of a vector. (This process can contain *Tokenization, Vectorization, etc*)\n",
    "\n",
    "Feature Extraction aims to reduce the number of features in a dataset by creating new features from the existing ones (and then discarding the original features)\n",
    "\n",
    "***Feature Extraction advantages:***\n",
    "- Accuracy improvements.\n",
    "- Overfitting risk reduction.\n",
    "- Speed up in training.\n",
    "- Improved Data Visualization.\n",
    "- Increase in explainability of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FE using Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "analyze = count_vector.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'lerxst', 'wam', 'umd', 'edu', 'where', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac3', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', '15', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', '60s', 'early', '70s', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "print(analyze(twenty_train.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts = count_vector.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FE using TF, TF–TDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TF*** stands for \"Term Frequency\"\n",
    "\n",
    "***TF-TDF*** stands for “Term Frequency times Inverse Document Frequency”\n",
    "\n",
    "Longer documents will have higher average count values than shorter documents, even though they might talk about the same topics. \n",
    "\n",
    "To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called `tf` for Term Frequencies.\n",
    "\n",
    "<img src=\"./tf-idf equation.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer.fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of word only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf.fit(twenty_train.data, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7728359001593202"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = NB_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.79      0.77      0.78       319\n",
      "           comp.graphics       0.67      0.74      0.70       389\n",
      " comp.os.ms-windows.misc       0.20      0.00      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.56      0.77      0.65       392\n",
      "   comp.sys.mac.hardware       0.84      0.75      0.79       385\n",
      "          comp.windows.x       0.65      0.84      0.73       395\n",
      "            misc.forsale       0.93      0.65      0.77       390\n",
      "               rec.autos       0.87      0.91      0.89       396\n",
      "         rec.motorcycles       0.96      0.92      0.94       398\n",
      "      rec.sport.baseball       0.96      0.87      0.91       397\n",
      "        rec.sport.hockey       0.93      0.96      0.95       399\n",
      "               sci.crypt       0.67      0.95      0.78       396\n",
      "         sci.electronics       0.79      0.66      0.72       393\n",
      "                 sci.med       0.87      0.82      0.85       396\n",
      "               sci.space       0.83      0.89      0.86       394\n",
      "  soc.religion.christian       0.70      0.96      0.81       398\n",
      "      talk.politics.guns       0.69      0.91      0.79       364\n",
      "   talk.politics.mideast       0.85      0.94      0.89       376\n",
      "      talk.politics.misc       0.58      0.63      0.60       310\n",
      "      talk.religion.misc       0.89      0.33      0.49       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.76      0.76      0.75      7532\n",
      "            weighted avg       0.76      0.77      0.75      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245   0   0   1   0   1   0   0   1   0   2   1   1   2   2  41   2  11\n",
      "    5   4]\n",
      " [  1 287   0  12   4  31   1   0   0   1   0  26   5   2   8   2   2   1\n",
      "    6   0]\n",
      " [  2  55   1 134  13 112   2   0   1   3   1  31   4   4   8   5   2   1\n",
      "   14   1]\n",
      " [  0  11   1 300  15  11   3   5   0   0   1  11  23   0   5   0   1   2\n",
      "    3   0]\n",
      " [  0  12   1  22 289   5   3   5   1   1   0  14  10   3   3   1   4   2\n",
      "    9   0]\n",
      " [  1  25   2  11   1 332   0   0   0   0   0  13   0   2   4   1   2   1\n",
      "    0   0]\n",
      " [  0   6   0  35  17   3 253  16   4   1   4   6  16   7   6   2   5   4\n",
      "    5   0]\n",
      " [  0   1   0   2   0   0   4 360   3   2   2   3   0   0   4   0   4   2\n",
      "    9   0]\n",
      " [  0   0   0   1   0   0   2  13 365   0   0   4   0   0   0   1   3   4\n",
      "    5   0]\n",
      " [  1   1   0   0   1   1   0   6   0 345  16   0   0   0   5   6   2   2\n",
      "   11   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2 385   1   0   1   1   3   1   2\n",
      "    3   0]\n",
      " [  0   3   0   0   0   2   1   2   0   0   0 377   2   1   1   0   2   1\n",
      "    4   0]\n",
      " [  0  14   0  17   5   5   0   5   1   0   1  58 261  11   6   2   1   3\n",
      "    3   0]\n",
      " [  7   6   0   2   0   0   1   1   0   2   1   4   5 325   3  16   1   7\n",
      "   15   0]\n",
      " [  1   4   0   0   0   4   0   1   0   0   0   1   2   4 351   5   2   3\n",
      "   16   0]\n",
      " [  3   2   0   0   0   1   0   0   0   0   1   0   0   2   2 382   0   1\n",
      "    0   4]\n",
      " [  0   0   0   1   0   0   1   0   3   0   0   6   0   1   0   2 330   6\n",
      "   13   1]\n",
      " [  1   1   0   0   0   2   0   0   0   1   0   3   0   2   0   3   2 354\n",
      "    7   0]\n",
      " [  1   0   0   0   0   0   0   1   0   0   0   4   0   2  10   5  87   5\n",
      "  195   0]\n",
      " [ 47   2   0   0   0   0   0   0   0   0   1   2   0   3   3  70  22   5\n",
      "   12  84]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer(use_idf=False)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                ('tf', TfidfTransformer(use_idf=False)),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7052575677110993"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = TF_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.24      0.37       319\n",
      "           comp.graphics       0.71      0.60      0.65       389\n",
      " comp.os.ms-windows.misc       0.79      0.65      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.75      0.69       392\n",
      "   comp.sys.mac.hardware       0.86      0.68      0.76       385\n",
      "          comp.windows.x       0.88      0.68      0.77       395\n",
      "            misc.forsale       0.90      0.72      0.80       390\n",
      "               rec.autos       0.71      0.92      0.80       396\n",
      "         rec.motorcycles       0.84      0.91      0.87       398\n",
      "      rec.sport.baseball       0.86      0.85      0.86       397\n",
      "        rec.sport.hockey       0.90      0.93      0.91       399\n",
      "               sci.crypt       0.52      0.96      0.67       396\n",
      "         sci.electronics       0.78      0.52      0.63       393\n",
      "                 sci.med       0.82      0.76      0.79       396\n",
      "               sci.space       0.83      0.81      0.82       394\n",
      "  soc.religion.christian       0.34      0.98      0.51       398\n",
      "      talk.politics.guns       0.66      0.80      0.73       364\n",
      "   talk.politics.mideast       0.96      0.72      0.82       376\n",
      "      talk.politics.misc       1.00      0.17      0.29       310\n",
      "      talk.religion.misc       1.00      0.01      0.02       251\n",
      "\n",
      "                accuracy                           0.71      7532\n",
      "               macro avg       0.79      0.68      0.67      7532\n",
      "            weighted avg       0.79      0.71      0.69      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = TF_IDF_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.83      0.76      0.76      7532\n",
      "            weighted avg       0.82      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248805098247477"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.71      0.72       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.73      0.78      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.67      0.70       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.84      0.76      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.91      0.90      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.88      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.84      0.96      0.90       396\n",
      "         sci.electronics       0.83      0.62      0.71       393\n",
      "                 sci.med       0.87      0.86      0.87       396\n",
      "               sci.space       0.84      0.96      0.90       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.41      0.55       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.83      0.81      0.81      7532\n",
      "            weighted avg       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data = [clean(letter) for letter in twenty_train.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lerxst wam umd edu thing subject car nntp post host rac wam umd edu organization university maryland college park line wonder anyone could enlighten car saw day door sport car look late early call bricklin doors really small addition front bumper separate rest body know anyone tellme model name engine specs years production car make history whatever info funky look car please mail thank bring neighborhood lerxst\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_data = [clean(letter) for letter in twenty_test.data]\n",
    "len(processed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVM to training models with preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(processed_train_data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177110993096123"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(processed_test_data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.69      0.71       319\n",
      "           comp.graphics       0.79      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.71      0.74      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.67      0.70       392\n",
      "   comp.sys.mac.hardware       0.81      0.78      0.80       385\n",
      "          comp.windows.x       0.85      0.77      0.81       395\n",
      "            misc.forsale       0.81      0.85      0.83       390\n",
      "               rec.autos       0.89      0.87      0.88       396\n",
      "         rec.motorcycles       0.92      0.96      0.94       398\n",
      "      rec.sport.baseball       0.89      0.91      0.90       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.82      0.95      0.88       396\n",
      "         sci.electronics       0.80      0.64      0.71       393\n",
      "                 sci.med       0.88      0.86      0.87       396\n",
      "               sci.space       0.84      0.95      0.89       394\n",
      "  soc.religion.christian       0.73      0.94      0.83       398\n",
      "      talk.politics.guns       0.69      0.93      0.79       364\n",
      "   talk.politics.mideast       0.91      0.93      0.92       376\n",
      "      talk.politics.misc       0.90      0.56      0.69       310\n",
      "      talk.religion.misc       0.83      0.39      0.53       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.82      0.81      0.80      7532\n",
      "            weighted avg       0.82      0.82      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
